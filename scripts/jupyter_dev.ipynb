{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f927cb2-379c-49e6-940a-293a6a559cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /Users/mateo.wheeler/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents - HF Mac/py-projects/coros-run-metrics/coros/lib/python3.13/site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a585963-b5ba-4479-86ee-7c6a5bf3b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89215e50-bac6-4a13-82df-3d5b917501f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/05 11:32:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.233:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Demo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10c4f6120>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('Spark Demo').master('local[*]').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04195993-a8d3-4d12-9df4-3b35ac66db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitdecode\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# spark libs\n",
    "import functools\n",
    "from functools import reduce\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import DataFrame\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import isnan, when, count, col, row_number\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f46619-8e34-4019-9c5a-5ea82b43e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecodeFit_DataFrame(file_path: str, frame_name: str = 'record', lat_long_update: bool = True, debug: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        file_path (str): path of raw fit file\n",
    "        frame_name (str, optional): _description_. Defaults to 'record'.\n",
    "        lat_long_update (bool, optional): _description_. Defaults to True.\n",
    "        debug (bool, optional): _description_. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: processed dataframe from source fit file\n",
    "    \"\"\"\n",
    "    # Initialize some useful variables for the loops\n",
    "    check_list = good_list = []\n",
    "    list_check = {}\n",
    "    df_activity = pd.DataFrame([])\n",
    "\n",
    "    # Open the file with fitdecode\n",
    "    with fitdecode.FitReader(file_path) as file:\n",
    "        \n",
    "        # Iterate through the .FIT frames\n",
    "        for frame in file:\n",
    "            \n",
    "            # Procede if the frame object is the correct data type\n",
    "            if isinstance(frame, fitdecode.records.FitDataMessage):\n",
    "                \n",
    "                # Add the frames and their corresponding counts to a dictionary for debugging\n",
    "                if frame.name not in check_list:\n",
    "                    check_list.append(frame.name)\n",
    "                    list_check[frame.name] = 1\n",
    "                else:\n",
    "                    list_check.update({frame.name: list_check.get(frame.name) + 1})\n",
    "                \n",
    "                # If the current frame is a record, we'll reset the row_dict variable\n",
    "                # and add the field values for all fields in the good_list variable\n",
    "                if frame.name == frame_name:\n",
    "                    row_dict = {}\n",
    "                    for field in frame.fields: \n",
    "                        if field.name.find('unknown') < 0:\n",
    "                            if field.name not in good_list and field.name.find('unknown') < 0:\n",
    "                                good_list.append(field.name)\n",
    "                            row_dict[field.name] = frame.get_value(field.name)\n",
    "                    \n",
    "                    # Append this row's dictionary to the main dataframe\n",
    "                    df_activity = pd.concat([df_activity, pd.DataFrame([row_dict])], ignore_index = True)\n",
    "        \n",
    "        # Update the Long/Lat columns to standard degrees\n",
    "        if lat_long_update:\n",
    "            for column in ['position_lat', 'position_long']:\n",
    "                df_activity[column] = df_activity[column].apply(lambda x: x / ((2**32)/360))\n",
    "        \n",
    "        # If you want to check to see which frames are in the file, print the list_check variable\n",
    "        if debug:\n",
    "            print(list_check)\n",
    "\n",
    "    return df_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f0392c-3836-43fc-a4b7-e5d946a8aaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LakewoodTrailRun20241128074748', 'BoulderTrailRun20241126062604', 'BoulderTrailRun20241124062708', 'BoulderTrailRun20241205063840', 'BoulderTrailRun20241122063002']\n",
      "Processing 'LakewoodTrailRun20241128074748' complete\n",
      "Processing 'BoulderTrailRun20241126062604' complete\n",
      "Processing 'BoulderTrailRun20241124062708' complete\n",
      "Processing 'BoulderTrailRun20241205063840' complete\n",
      "Processing 'BoulderTrailRun20241122063002' complete\n",
      "Combined run event pandas dataframe has 21543 records\n"
     ]
    }
   ],
   "source": [
    "directory_path = '/Users/mateo.wheeler/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents - HF Mac/py-projects/coros-run-metrics/fit_files'\n",
    "file_list = []\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        filename = filename[:-4]\n",
    "        file_list.append(filename)\n",
    "\n",
    "print(file_list)\n",
    "\n",
    "df_activity_combined = pd.DataFrame([])\n",
    "for file in file_list:\n",
    "\n",
    "\n",
    "    df_activity = DecodeFit_DataFrame(f'{directory_path}/{file}.fit', frame_name = 'record')\n",
    "\n",
    "    df_activity['elapsed_time'] = df_activity['timestamp'].apply(lambda x: x - df_activity.loc[0, 'timestamp'])\n",
    "    df_activity['distance_miles'] = df_activity['distance']*0.000621371192\n",
    "    df_activity['altitude_feet'] = df_activity['altitude']*3.28084\n",
    "    df_activity['pace_minutes_per_mile'] = 26.8224/df_activity['speed']\n",
    "    df_activity['timestamp'] = pd.to_datetime(df_activity['timestamp'])\n",
    "    df_activity['run'] = file\n",
    "\n",
    "    df_activity_combined = pd.concat([df_activity_combined, df_activity], ignore_index = True)\n",
    "\n",
    "    print(f\"Processing '{file}' complete\")\n",
    "\n",
    "print(f\"Combined run event pandas dataframe has {len(df_activity_combined)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a90047bc-0b3b-4c11-87fd-e4eb622b1d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+----------------+----------------+\n",
      "|                 run|             min_ts|             max_ts|run_time_seconds|run_time_minutes|\n",
      "+--------------------+-------------------+-------------------+----------------+----------------+\n",
      "|LakewoodTrailRun2...|2024-11-28 07:47:48|2024-11-28 08:55:04|            4036|            67.0|\n",
      "|BoulderTrailRun20...|2024-11-26 06:26:04|2024-11-26 07:22:09|            3365|            56.0|\n",
      "|BoulderTrailRun20...|2024-11-24 06:27:08|2024-11-24 08:34:17|            7629|           127.0|\n",
      "|BoulderTrailRun20...|2024-12-05 06:38:40|2024-12-05 07:44:51|            3971|            66.0|\n",
      "|BoulderTrailRun20...|2024-11-22 06:30:02|2024-11-22 07:28:54|            3532|            59.0|\n",
      "+--------------------+-------------------+-------------------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_run_events = spark.createDataFrame(df_activity_combined)\n",
    "df_run_events = df_run_events.replace(float('inf'), None)\\\n",
    ".fillna(0)\n",
    "\n",
    "df_ts_agg = df_run_events.groupby('run').agg(min('timestamp').alias('min_ts'), max('timestamp').alias('max_ts'))\n",
    "\n",
    "df_ts_agg = df_ts_agg.withColumn('run_time_seconds',col(\"max_ts\").cast(\"long\") - col('min_ts').cast(\"long\"))\\\n",
    ".withColumn('run_time_minutes',round(col('run_time_seconds')/60))\n",
    "\n",
    "df_ts_agg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a57093d8-0720-44a8-b6a3-220f3dda26e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('run', 'string'),\n",
       " ('activity_type', 'string'),\n",
       " ('timestamp', 'timestamp'),\n",
       " ('distance', 'double'),\n",
       " ('enhanced_speed', 'double'),\n",
       " ('speed', 'double'),\n",
       " ('Effort Pace', 'double'),\n",
       " ('enhanced_altitude', 'double'),\n",
       " ('altitude', 'double'),\n",
       " ('step_length', 'double'),\n",
       " ('cadence', 'double'),\n",
       " ('heart_rate', 'double'),\n",
       " ('power', 'double'),\n",
       " ('accumulated_power', 'double'),\n",
       " ('position_lat', 'double'),\n",
       " ('position_long', 'double'),\n",
       " ('elapsed_time', 'interval day to second'),\n",
       " ('distance_miles', 'double'),\n",
       " ('altitude_feet', 'double'),\n",
       " ('pace_minutes_per_mile', 'double'),\n",
       " ('min_ts', 'timestamp'),\n",
       " ('max_ts', 'timestamp'),\n",
       " ('run_time_seconds', 'bigint'),\n",
       " ('run_time_minutes', 'double')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_run_events2 = df_run_events.join(df_ts_agg, ['run'], 'left')\n",
    "df_run_events2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cd8cfaa-2f46-47ff-ad68-deb36e9bc809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|pace_minutes_per_mile|\n",
      "+---------------------+\n",
      "|                  0.0|\n",
      "|                  0.0|\n",
      "|                  0.0|\n",
      "|                  0.0|\n",
      "|                  0.0|\n",
      "|                  0.0|\n",
      "|                  0.0|\n",
      "|                  0.0|\n",
      "|                  0.0|\n",
      "|    18.05006729475101|\n",
      "|    9.015932773109244|\n",
      "|    9.092338983050846|\n",
      "|    9.160655737704918|\n",
      "|    9.188900308324769|\n",
      "|    9.214153211954654|\n",
      "|    9.258681394546082|\n",
      "|    9.303642039542144|\n",
      "|    9.391596638655463|\n",
      "|     9.47453196750265|\n",
      "|    9.541942369263607|\n",
      "+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <_io.BufferedWriter name=5>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mateo.wheeler/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents - HF Mac/py-projects/coros-run-metrics/coros/lib/python3.13/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 193, in manager\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "df_run_events2.select('pace_minutes_per_mile').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77ce54ee-8fee-47c9-b1a6-350c37c40cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+----------------+-------------------+--------------------------+-----------------+------------------+----------+-----------------+------------+------------------+---------------+\n",
      "|activity_type|                 run|run_time_minutes|max(distance_miles)|avg(pace_minutes_per_mile)| approx_best_pace|        avg(power)|max(power)|     avg(cadence)|max(cadence)|   avg(heart_rate)|max(heart_rate)|\n",
      "+-------------+--------------------+----------------+-------------------+--------------------------+-----------------+------------------+----------+-----------------+------------+------------------+---------------+\n",
      "|      running|LakewoodTrailRun2...|            67.0|  6.802237430790879|         9.849714544181122|6.677221807318894|220.38679490512087|     471.0|83.18377956849493|       124.0|152.87210813621004|          192.0|\n",
      "|      running|BoulderTrailRun20...|            56.0|   6.19372862246528|          9.27750633259695|           6.7056|217.53021560886728|     356.0|83.88733677497723|       106.0| 151.4986334649256|          170.0|\n",
      "|      running|BoulderTrailRun20...|           127.0|  11.73351377504592|        10.817553520134558|7.681099656357388|195.83101142379493|     497.0|82.14196154917805|       123.0|160.37809974923377|          191.0|\n",
      "|      running|BoulderTrailRun20...|            66.0|   7.18290806414584|         9.429260667985913|7.027089337175791|212.82168367346938|     472.0|84.35637755102042|       105.0|152.69591836734693|          183.0|\n",
      "|      running|BoulderTrailRun20...|            59.0|  6.123283770428239|         9.172250999992468|6.966857142857142| 213.7824508320726|     355.0|82.35128593040847|       112.0|153.72950075642964|          187.0|\n",
      "+-------------+--------------------+----------------+-------------------+--------------------------+-----------------+------------------+----------+-----------------+------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_run_events2.groupby('activity_type','run','run_time_minutes').agg(max('distance_miles'), \n",
    "                                avg('pace_minutes_per_mile'), \n",
    "                                *[expr(f\"approx_percentile(pace_minutes_per_mile, {q}) as approx_best_pace\") for q in [0.10]],\n",
    "                                avg('power'),\n",
    "                                max('power'),\n",
    "                                avg('cadence'),\n",
    "                                max('cadence'),\n",
    "                                avg('heart_rate'),\n",
    "                                max('heart_rate')\n",
    "                                ).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
